{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from sklearn import metrics\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import auc as skAUC\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, TensorBoard\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import time\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from keras import backend as K \n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "path = pathlib.Path.cwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch ## pip3 install -U keras-tuner "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data (please DIY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rinv = \"0p3\"\n",
    "file_path = \"LL-\"+rinv+\".h5\"\n",
    "hdf_file = path/file_path\n",
    "hf = h5py.File(hdf_file, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hf[\"features\"][:]\n",
    "Y = hf[\"targets\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X)\n",
    "Ntrain, Nval, Ntest = int(N/5*4),  int(N/10),  int(N/10)\n",
    "Xim_train, Xim_val, Xim_test = X[:Ntrain], X[Ntrain:Nval+Ntrain], X[Nval+Ntrain:N]\n",
    "yim_train, yim_val, yim_test = Y[:Ntrain], Y[Ntrain:Nval+Ntrain], Y[Nval+Ntrain:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_filter(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=1):\n",
    "        super(get_filter, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "        wq_init = tf.random_normal_initializer()\n",
    "#         wq_init = tf.zeros_initializer()\n",
    "        self.ft = tf.Variable(initial_value=wq_init(shape=( input_shape[1], input_shape[2], self.units), dtype='float32'), trainable=True, name='Basisfinder_ft')\n",
    "        self.shape = input_shape\n",
    "#         super(Basisfilter, self).build()\n",
    "        \n",
    "    def call(self, inputs):  # Defines the computation from inputs to outputs\n",
    "#         inputs = tf.expand_dims(inputs, axis=-1)\n",
    "#         inputs = tf.tile(inputs,[1,1,1,self.units])\n",
    "#         b = inputs - self.ft\n",
    "        b = tf.math.abs(self.ft)\n",
    "#         b = tf.math.sign(b)-0.6\n",
    "#         b = (tf.math.sign(b) +1)/2\n",
    "        return inputs*b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    inputs = tf.keras.Input(shape=(32,32))\n",
    "  \n",
    "    lr = hp.Choice('learning_rate', values=[i*1e-4 for i in range(10)])\n",
    "#     batch = hp.Int('batch_size', min_value=32, max_value=512, step=16)\n",
    "    convk1 = hp.Int('convk_1', min_value=1, max_value = 4, step=1)\n",
    "    convp1 = hp.Int('convp_1', min_value=32, max_value =256, step=8, parent_values=[convk1])\n",
    "    \n",
    "    pool1 = hp.Int('pooling_1', min_value=2, max_value = 3, step=1, parent_values=[convk1, convp1])\n",
    "    \n",
    "    convk2 = hp.Int('convk_2', min_value=1, max_value = 4, step=1)\n",
    "    convp2 = hp.Int('convp_2', min_value=32, max_value = 256, step=8, parent_values=[convk2])\n",
    "    \n",
    "    \n",
    "    convk3 = hp.Int('convk_3', min_value=1, max_value = 4, step=1)\n",
    "    convp3 = hp.Int('convp_3', min_value=32, max_value = 256, step=8, parent_values=[convk3])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x = inputs\n",
    "    x = tf.expand_dims(x,axis=-1)\n",
    "    x = get_filter(1)(x)\n",
    "    x = tf.keras.layers.Conv2D(convp1, kernel_size=(convk1, convk1), activation='relu', input_shape=(32,32,1))(x)\n",
    "#     x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(pool1, pool1))(x)\n",
    "    \n",
    "#     x = tf.keras.layers.Conv2D(56, kernel_size=(3,3), activation='relu', input_shape=(64,64,32))(x)\n",
    "    x = tf.keras.layers.Conv2D(convp2, kernel_size=(convk2, convk2), activation='relu')(x)\n",
    "    \n",
    "#     x = tf.keras.layers.Conv2D(56, kernel_size=(3,3), activation='relu', input_shape=(15,15,64))(x)\n",
    "    x = tf.keras.layers.Conv2D(convp3, kernel_size=(convk3, convk3), activation='relu')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    dns1 = hp.Int('units_1', min_value=32, max_value=512, step=32, parent_values=[x.shape[1]])\n",
    "    dp1 = hp.Choice('Dropout_1', values=[i/10 for i in range(10)], parent_values=[dns1])\n",
    "    dns2 = hp.Int('units_2', min_value=32, max_value=256, step=32, parent_values=[dp1, dns1])\n",
    "    dp2 = hp.Choice('Dropout_2', values=[i/10 for i in range(6)], parent_values=[dp1, dns1, dns2])\n",
    "    x = tf.keras.layers.Dense(dns1, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(dp1)(x)\n",
    "    x = tf.keras.layers.Dense(dns2, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(dp2)(x)\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    modelCNN_basis = tf.keras.Model(inputs=inputs, outputs=x, name='CNN_basis')\n",
    "    modelCNN_basis.compile(optimizer=keras.optimizers.Adam(lr) ,\n",
    "                     loss=\"binary_crossentropy\",\n",
    "                     metrics=['accuracy'])\n",
    "    print(hp.values)\n",
    "    modelCNN_basis.summary()\n",
    "#     print(\"Droup out :\", dp1, \" \", dp2)\n",
    "#     print(\"lr :\", lr)\n",
    "                           \n",
    "    return modelCNN_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(build_model, objective='val_loss',max_trials=10, executions_per_trial=1,directory='./Keras_Tunner', project_name='CNN'+rinv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(Xim_train, yim_train, epochs=5, batch_size=512, validation_data=(Xim_val, yim_val), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = tuner.get_best_hyperparameters(num_trials=1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpdic = HP.values \n",
    "# w = csv.writer(open('./Keras_Tunner/best_all_CNN_model_'+rinv+'.csv', \"w\"))\n",
    "with open('./Keras_Tunner/best_all_CNN_model_'+rinv+'.csv', \"w\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames= hpdic.keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows([hpdic])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Keras_Tunner/best_all_CNN_model_'+rinv+'.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    my_list = list(reader)\n",
    "hpdirc = {my_list[0][i]:[my_list[1][i]] for i in range(len(my_list[0]))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(hp):\n",
    "    inputs = tf.keras.Input(shape=(32,32))\n",
    "  \n",
    "    lr = float(hp['learning_rate'][0])\n",
    "#     batch = hp.Int('batch_size', min_value=32, max_value=512, step=16)\n",
    "    convk1 = int(hp['convk_1'][0])\n",
    "    convp1 = int(hp['convp_1'][0])\n",
    "    \n",
    "    pool1 = int(hp['pooling_1'][0])\n",
    "    \n",
    "    convk2 = int(hp['convk_2'][0])\n",
    "    convp2 = int(hp['convp_2'][0])\n",
    "    \n",
    "    \n",
    "    convk3 = int(hp['convk_3'][0])\n",
    "    convp3 = int(hp['convp_3'][0])\n",
    "    \n",
    "    dns1 = int(hp['units_1'][0])\n",
    "    dp1 = float(hp['Dropout_1'][0])\n",
    "    dns2 = int(hp['units_2'][0])\n",
    "    dp2 = float(hp['Dropout_2'][0])\n",
    "    \n",
    "    \n",
    "    x = inputs\n",
    "    x = tf.expand_dims(x,axis=-1)\n",
    "    x = get_filter(1)(x)\n",
    "    x = tf.keras.layers.Conv2D(convp1, kernel_size=(convk1, convk1), activation='relu', input_shape=(32,32,1))(x)\n",
    "#     x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(pool1, pool1))(x)\n",
    "    \n",
    "#     x = tf.keras.layers.Conv2D(56, kernel_size=(3,3), activation='relu', input_shape=(64,64,32))(x)\n",
    "    x = tf.keras.layers.Conv2D(convp2, kernel_size=(convk2, convk2), activation='relu')(x)\n",
    "    \n",
    "#     x = tf.keras.layers.Conv2D(56, kernel_size=(3,3), activation='relu', input_shape=(15,15,64))(x)\n",
    "    x = tf.keras.layers.Conv2D(convp3, kernel_size=(convk3, convk3), activation='relu')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "\n",
    "    x = tf.keras.layers.Dense(dns1, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(dp1)(x)\n",
    "    x = tf.keras.layers.Dense(dns2, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(dp2)(x)\n",
    "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    modelCNN_basis = tf.keras.Model(inputs=inputs, outputs=x, name='CNN_basis')\n",
    "    modelCNN_basis.compile(optimizer=keras.optimizers.Adam(lr) ,\n",
    "                     loss=\"binary_crossentropy\",\n",
    "                     metrics=['accuracy'])\n",
    "    print(hp.values)\n",
    "    modelCNN_basis.summary()\n",
    "#     print(\"Droup out :\", dp1, \" \", dp2)\n",
    "#     print(\"lr :\", lr)\n",
    "                           \n",
    "    return modelCNN_basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN_basis = get_model(hpdirc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "opt = [\"Adadelta\", \"SGD\", \"Adagrad\", \"Adam\"]\n",
    "optn = opt[i]\n",
    "opts = {\"Adadelta\":[tf.keras.optimizers.Adadelta()], \"SGD\":[tf.keras.optimizers.SGD()], \n",
    "        \"Adagrad\":[tf.keras.optimizers.Adagrad()], \"Adam\":[tf.keras.optimizers.Adam(learning_rate = float(hpdirc['learning_rate'][0]))]}\n",
    "optimizer =opts[optn][0]\n",
    "\n",
    "# modelCNN.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "modelCNN_basis.compile(optimizer= optimizer, loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "modelCNN_basis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"CNN_basis\"\n",
    "save_dir = './Keras_Tunner/'\n",
    "model_name = '%s_model.test.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "# lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# progress_bar = keras.callbacks.ProgbarLogger()\n",
    "\n",
    "# csv_logger = keras.callbacks.CSVLogger(save_dir+'CNN'+rinv+'.csv')\n",
    "# csv_logger = keras.callbacks.CSVLogger(save_dir+'CNN_'+rinv+'_'+optn+'_filter.csv')\n",
    "csv_logger = keras.callbacks.CSVLogger(save_dir+'CNN_all_'+rinv+'_'+optn+'_filter.csv')\n",
    "\n",
    "\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "                            monitor='val_loss',\n",
    "                            min_delta=1e-4,\n",
    "                            patience=3,\n",
    "                            verbose=1,\n",
    "                            mode='min', baseline=None, ## 'min' \n",
    "                            restore_best_weights=True)\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=2, min_lr=0.00001)\n",
    "callbacks = [checkpoint, csv_logger,  earlystop ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN_basis.fit(Xim_train, yim_train , validation_data=(Xim_val, yim_val), callbacks = callbacks, shuffle=True , epochs=400, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCNN_basis.save(\"./Keras_Tunner/CNN_all_\"+rinv+\"_\"+optn+\"_filter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
